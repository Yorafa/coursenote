# Time Series Sample

Given a stationary time series $x_t$, we can generate a sample mean $\bar x = \frac{1}{n} \sum_{t=1}^n x_t$ with $E[\bar x] = \mu$ and $Var[\bar x] = \frac{1}{n} \sum_{h = -n}^{n} (1-|h|/n) \gamma_x(h)$, we also have:
- sample autocovariance function: $\hat \gamma_x(h) = \frac{1}{n} \sum_{t=1}^{n-h} (x_t - \bar x)(x_{t+h} - \bar x)$ with $\hat \gamma(h) = \hat \gamma(-h)$
  - This estimator of autocovariance function is preferred to be dividing by $n - h$ then it's non-negative definite function.
  - When dividing by $n$ or $n - h$, it's an unbiased estimator of autocovariance function ($\gamma(h)$).
- sample autocorrelation function: $\hat \rho_x(h) = \frac{\hat \gamma_x(h)}{\sqrt{\hat \gamma_x(0)\hat \gamma_x(h)}} = \frac{\hat \gamma_x(h)}{\hat \gamma_x(0)}$

Since we have sample ACF, we can use hypothesis test to test whether a time series with lag.
- 95% of ACFs should be within $\pm 2/\sqrt{n}$, if not, we indicates a peak/lag in the ACF.
- t-test statistic $t_{\rho(h)} = \frac{\hat \rho(h)}{\sigma_{\hat \rho(h)}}$ and we reject when $t_{\rho(h)} > 2$ where $\sigma_{\hat \rho(h)} = 1/\sqrt{n}$.

For joint time series, we also can have sample estimators:
- sample cross-covariance function: $\hat \gamma_{xy}(h) = \frac{1}{n} \sum_{t=1}^{n-h} (x_{t+h} - \bar x)(y_t - \bar y)$ where $\hat \gamma_{xy}(h) = \hat \gamma_{yx}(-h)$ determines the function for negative lags.
- sample cross-correlation function: $\hat \rho_{xy}(h) = \frac{\hat \gamma_{xy}(h)}{\sqrt{\hat \gamma_{x}(0)\hat \gamma_{y}(0)}}$
- $\hat \rho_{xy}(h)$ with mean zero and variance $\frac{1}{n}$ if at least one of processes is independent white noise

## Model to analyze process

To get a time series model, we may need to do pre-processing and filtering to the data. Some operations examples:
- detrending: remove all elements of noise (trends, periodicity, autocorrelation, seasonality, etc.) in the data and transform non-stationary data into stationary data (we will introduce later)
- removing outliers: remove the extreme values in the data.
- Smoothing: using exponential or moving average method to get the rid of the noise in the series. Or using the centered moving average method.

### Random Walk with drift model

To analyzing trends, we would like to use Random walk with drift model. Formally, we define model $x_t = \delta + x_{t - 1} + w_t$ a **random walk (unit-root) with drift**, where 
- $w_t$ is a white noise $w_t \sim wn(0, \sigma^2), t \ge 1$
- $\delta$ is the drift term, $\delta = 0 \implies $ such model called a random walk.
- A word description of such model is: the value of $x$ in period $t$ is equal to its value in $t - 1$ plus a random step due to the white-noise shock $w_t$ and a drift term $\delta$.
- some times we would like to extend last period, so that we have $x_t = \delta t + \sum_{i=1}^{t} w_i$ where $x_{t - 1} = \delta + x_{t - 2} + w_{t - 1}$ and recursively back.
- $\gamma_{x}(s, t) = Cov(x_s, x_t) = Cov(\sum_{j = 1}^s w_j, \sum_{i = 1}^t w_i) = \min(s,t)\sigma^2_w$ (will introduce later)

### Autoregressive Model

A enhanced model is **autoregressive model of order** (AR in short) is $x_t + \phi x_{t - 1} + w_t$, where $w_t \sim wn(0, \sigma^2)$
- AR is random walk series when root $\phi = 1$ (that's why called unit-root)
- We will talk more about AR model later. (like ARIMA model)

### ACF V.S. PACF among different models

| Model | ACF | PACF |
| :---: | :---: | :---: |
|White noise| All zeros | All zeros |
|AR(p)| Tails off as exponetial decay |Cuts off after lag p|
|MA(q)| Cuts off after lag q | Tails off as exponential decay|
|ARMA(p, q)| Decay beginning at lag q| Decay beginning at lag p|
|Random walk| No decay to zero | Cuts off after lag 1|
